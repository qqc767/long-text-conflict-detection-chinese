from splitter import split_sentences
from translator import ChineseToEnglishTranslator
from nli_detector import DetectConflicts
import sys

sys.stdout = open('conflict_detection.log', 'w', encoding='utf-8')

def read_text_file(filepath: str) -> str:
    with open(filepath, 'r', encoding='utf-8') as f:
        return f.read()

if __name__ == "__main__":
    # è¯»å–æ–‡ä»¶å†…å®¹
    chinese_text = read_text_file('input_text_2.txt')

    print("ğŸ”¹ Step 1: ä¸­æ–‡åˆ†å¥")
    sentences = split_sentences(chinese_text)
    # print(sentences)

    print("ğŸ”¹ Step 2: ç¿»è¯‘ä¸ºè‹±æ–‡")
    translator = ChineseToEnglishTranslator()
    en_cn_map = translator.translate(sentences)
    # for en, zh in en_cn_map.items():
    #     print(f"[ZH] {zh}\n[EN] {en}\n")

    print("ğŸ”¹ Step 3: è¿›è¡ŒNLIå†²çªæ£€æµ‹")
    # æå–è‹±æ–‡å¥å­åˆ—è¡¨ï¼ˆä¼ ç»™ NLI æ£€æµ‹ï¼‰
    en_sentences = list(en_cn_map.keys())

    # è¿›è¡Œè‹±æ–‡å†²çªæ£€æµ‹
    conflicts_en = DetectConflicts().detect_batch(en_sentences)

    print("\nğŸ” æ£€æµ‹åˆ°çš„å†²çªå¯¹:")
    for en1, en2, prob in conflicts_en:
        cn1 = en_cn_map.get(en1, "")
        cn2 = en_cn_map.get(en2, "")
        print(f"ğŸŸ¥ å†²çª:\n - {cn1}\n - {cn2}\n - æ¦‚ç‡: {prob:.4f}")
